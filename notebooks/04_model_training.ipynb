{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training\n",
        "\n",
        "Train regression and classification models for shelter occupancy prediction.\n",
        "\n",
        "**Regression Models:**\n",
        "- Linear Regression (baseline)\n",
        "- Random Forest Regressor (production-ready)\n",
        "- XGBoost Regressor (best performance)\n",
        "\n",
        "**Classification Models:**\n",
        "- Logistic Regression (baseline)\n",
        "- XGBoost Classifier (best performance)\n",
        "- Random Forest Classifier (backup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train data...\n",
            "Training on 132641 samples with 33 features\n",
            "Regression target range: 3.33 to 101.61\n",
            "Classification target distribution: [ 25216 107425]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "def get_project_root():\n",
        "    \"\"\"Find the project root directory by looking for a marker file/directory.\"\"\"\n",
        "    # Start from current working directory\n",
        "    current = Path(os.getcwd())\n",
        "    \n",
        "    # Look for project markers (like .git, requirements.txt, or data/ directory)\n",
        "    markers = ['.git', 'requirements.txt', 'data', 'notebooks']\n",
        "    \n",
        "    # Walk up the directory tree\n",
        "    for path in [current] + list(current.parents):\n",
        "        # Check if this looks like the project root\n",
        "        if any((path / marker).exists() for marker in markers):\n",
        "            return path\n",
        "    \n",
        "    # Fallback: if we're in notebooks/, go up one level\n",
        "    if current.name == 'notebooks':\n",
        "        return current.parent\n",
        "    \n",
        "    # Last resort: current directory\n",
        "    return current\n",
        "\n",
        "project_root = get_project_root()\n",
        "processed_dir = project_root / \"data\" / \"processed\"\n",
        "models_dir = project_root / \"models\"\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Loading train data...\")\n",
        "train_df = pd.read_csv(processed_dir / \"train.csv\")\n",
        "\n",
        "# Load feature list\n",
        "with open(processed_dir / \"feature_list.txt\", 'r') as f:\n",
        "    feature_cols = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Prepare features and targets\n",
        "X_train = train_df[feature_cols].values\n",
        "y_train_reg = train_df['OCCUPANCY_RATE_BEDS'].values\n",
        "y_train_clf = train_df['overcapacity'].values\n",
        "\n",
        "print(f\"Training on {len(X_train)} samples with {len(feature_cols)} features\")\n",
        "print(f\"Regression target range: {y_train_reg.min():.2f} to {y_train_reg.max():.2f}\")\n",
        "print(f\"Classification target distribution: {np.bincount(y_train_clf)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regression Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Training Linear Regression...\n",
            "   ✓ Saved to models/regression_lr.pkl\n"
          ]
        }
      ],
      "source": [
        "# Baseline: Linear Regression\n",
        "print(\"1. Training Linear Regression...\")\n",
        "lr_reg = LinearRegression()\n",
        "lr_reg.fit(X_train, y_train_reg)\n",
        "joblib.dump(lr_reg, models_dir / \"regression_lr.pkl\")\n",
        "print(\"   ✓ Saved to models/regression_lr.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2. Training Random Forest Regressor...\n",
            "   ✓ Saved to models/regression_rf.pkl\n"
          ]
        }
      ],
      "source": [
        "# Production: Random Forest Regressor\n",
        "print(\"2. Training Random Forest Regressor...\")\n",
        "rf_reg = RandomForestRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_reg.fit(X_train, y_train_reg)\n",
        "joblib.dump(rf_reg, models_dir / \"regression_rf.pkl\")\n",
        "print(\"   ✓ Saved to models/regression_rf.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3. Training XGBoost Regressor...\n",
            "   ✓ Saved to models/regression_xgb.pkl\n"
          ]
        }
      ],
      "source": [
        "# Advanced: XGBoost Regressor\n",
        "print(\"3. Training XGBoost Regressor...\")\n",
        "xgb_reg = XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=8,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_reg.fit(X_train, y_train_reg)\n",
        "joblib.dump(xgb_reg, models_dir / \"regression_xgb.pkl\")\n",
        "print(\"   ✓ Saved to models/regression_xgb.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classification Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Training Logistic Regression...\n",
            "   ✓ Saved to models/classification_lr.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/ml-shelter/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 10000 iteration(s) (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
            "\n",
            "Increase the number of iterations to improve the convergence (max_iter=10000).\n",
            "You might also want to scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Baseline: Logistic Regression\n",
        "print(\"1. Training Logistic Regression...\")\n",
        "log_clf = LogisticRegression(class_weight='balanced', max_iter=10000, random_state=42, n_jobs=-1)\n",
        "log_clf.fit(X_train, y_train_clf)\n",
        "joblib.dump(log_clf, models_dir / \"classification_lr.pkl\")\n",
        "print(\"   ✓ Saved to models/classification_lr.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2. Training XGBoost Classifier...\n",
            "   ✓ Saved to models/classification_xgb.pkl\n"
          ]
        }
      ],
      "source": [
        "# Production: XGBoost Classifier\n",
        "print(\"2. Training XGBoost Classifier...\")\n",
        "xgb_clf = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    scale_pos_weight=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_clf.fit(X_train, y_train_clf)\n",
        "joblib.dump(xgb_clf, models_dir / \"classification_xgb.pkl\")\n",
        "print(\"   ✓ Saved to models/classification_xgb.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3. Training Random Forest Classifier...\n",
            "   ✓ Saved to models/classification_rf.pkl\n"
          ]
        }
      ],
      "source": [
        "# Backup: Random Forest Classifier\n",
        "print(\"3. Training Random Forest Classifier...\")\n",
        "rf_clf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=20,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_clf.fit(X_train, y_train_clf)\n",
        "joblib.dump(rf_clf, models_dir / \"classification_rf.pkl\")\n",
        "print(\"   ✓ Saved to models/classification_rf.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved feature columns to models/feature_columns.pkl\n",
            "\n",
            "✓ All models trained successfully!\n"
          ]
        }
      ],
      "source": [
        "# Save feature columns for inference\n",
        "joblib.dump(feature_cols, models_dir / \"feature_columns.pkl\")\n",
        "print(\"✓ Saved feature columns to models/feature_columns.pkl\")\n",
        "print(\"\\n✓ All models trained successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (ml-shelter)",
      "language": "python",
      "name": "ml-shelter"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
